{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anameka South - ACCESS CM2 SSP585 CMIP6 Data Extraction\n",
    "\n",
    "This notebook extracts time series data for filtered grid points from CMIP6 climate model datasets.\n",
    "\n",
    "## Model: ACCESS_CM2_SSP585\n",
    "## Variables: tasmax, tasmin, pr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Imports and Configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T14:55:39.447732Z",
     "iopub.status.busy": "2025-12-14T14:55:39.447540Z",
     "iopub.status.idle": "2025-12-14T14:55:44.186911Z",
     "shell.execute_reply": "2025-12-14T14:55:44.186562Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration loaded:\n",
      "  - Coordinates file: C:\\Users\\ibian\\Desktop\\ClimAdapt\\Anameka\\Grid\\filtered_grid_points.json\n",
      "  - Data directory: C:\\Users\\ibian\\Desktop\\ClimAdapt\\CMIP6\\ACCESS CM2 xlsx\\ACCESS_CM2_SSP585_merged\n",
      "  - Output directory: C:\\Users\\ibian\\Desktop\\ClimAdapt\\Anameka\\Anameka_South_ACCESS_CM2_SSP585\n",
      "  - Coordinate tolerance: 0.001 degrees\n",
      "  - Variables: tasmax, tasmin, pr\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Configuration\n",
    "COORDINATES_FILE = r\"C:\\Users\\ibian\\Desktop\\ClimAdapt\\Anameka\\Grid\\filtered_grid_points.json\"\n",
    "DATA_DIR = r\"C:\\Users\\ibian\\Desktop\\ClimAdapt\\CMIP6\\ACCESS CM2 xlsx\\ACCESS_CM2_SSP585_merged\"\n",
    "OUTPUT_DIR = r\"C:\\Users\\ibian\\Desktop\\ClimAdapt\\Anameka\\Anameka_South_ACCESS_CM2_SSP585\"\n",
    "MODEL_NAME = \"ACCESS_CM2_SSP585\"\n",
    "COORD_TOLERANCE = 0.001  # degrees (approximately 111 meters)\n",
    "\n",
    "# Variables to process\n",
    "VARIABLES = ['tasmax', 'tasmin', 'pr']\n",
    "\n",
    "# Ensure output directory exists\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"Configuration loaded:\")\n",
    "print(f\"  - Coordinates file: {COORDINATES_FILE}\")\n",
    "print(f\"  - Data directory: {DATA_DIR}\")\n",
    "print(f\"  - Output directory: {OUTPUT_DIR}\")\n",
    "print(f\"  - Coordinate tolerance: {COORD_TOLERANCE} degrees\")\n",
    "print(f\"  - Variables: {', '.join(VARIABLES)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Filtered Coordinates\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T14:55:44.218017Z",
     "iopub.status.busy": "2025-12-14T14:55:44.217811Z",
     "iopub.status.idle": "2025-12-14T14:55:44.233284Z",
     "shell.execute_reply": "2025-12-14T14:55:44.232758Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 46 filtered grid points\n",
      "\n",
      "First few coordinates:\n",
      "     lat         lon\n",
      "0 -31.75  117.400002\n",
      "1 -31.75  117.449997\n",
      "2 -31.75  117.500000\n",
      "3 -31.75  117.550003\n",
      "4 -31.75  117.599998\n",
      "\n",
      "Coordinate range:\n",
      "  Latitude: -31.7500 to -31.4500\n",
      "  Longitude: 117.4000 to 117.7000\n"
     ]
    }
   ],
   "source": [
    "# Load filtered coordinates from JSON\n",
    "with open(COORDINATES_FILE, 'r', encoding='utf-8') as f:\n",
    "    filtered_coords = json.load(f)\n",
    "\n",
    "# Convert to DataFrame for easier handling\n",
    "coords_df = pd.DataFrame(filtered_coords)\n",
    "\n",
    "print(f\"Loaded {len(filtered_coords)} filtered grid points\")\n",
    "print(f\"\\nFirst few coordinates:\")\n",
    "print(coords_df.head())\n",
    "print(f\"\\nCoordinate range:\")\n",
    "print(f\"  Latitude: {coords_df['lat'].min():.4f} to {coords_df['lat'].max():.4f}\")\n",
    "print(f\"  Longitude: {coords_df['lon'].min():.4f} to {coords_df['lon'].max():.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Extraction Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T14:55:44.235358Z",
     "iopub.status.busy": "2025-12-14T14:55:44.235067Z",
     "iopub.status.idle": "2025-12-14T14:55:44.238777Z",
     "shell.execute_reply": "2025-12-14T14:55:44.238348Z"
    }
   },
   "outputs": [],
   "source": [
    "def extract_data_for_coordinates(excel_file_path, target_coords_df, tolerance=0.001):\n",
    "    \"\"\"\n",
    "    Extract time series data for specific coordinates from Excel file.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    excel_file_path : str\n",
    "        Path to the Excel file containing climate data\n",
    "    target_coords_df : pd.DataFrame\n",
    "        DataFrame with 'lat' and 'lon' columns for target coordinates\n",
    "    tolerance : float\n",
    "        Coordinate matching tolerance in degrees (default: 0.001)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        Filtered DataFrame with matching coordinates and all time series columns\n",
    "    \"\"\"\n",
    "    # Load Excel file\n",
    "    print(f\"  Loading data from: {os.path.basename(excel_file_path)}\")\n",
    "    df = pd.read_excel(excel_file_path)\n",
    "    \n",
    "    print(f\"  Total rows in dataset: {len(df):,}\")\n",
    "    \n",
    "    # Find matching rows using approximate coordinate matching\n",
    "    matched_indices = []\n",
    "    \n",
    "    for idx, target_row in target_coords_df.iterrows():\n",
    "        target_lat = target_row['lat']\n",
    "        target_lon = target_row['lon']\n",
    "        \n",
    "        # Find rows where coordinates match within tolerance\n",
    "        lat_match = abs(df['lat'] - target_lat) < tolerance\n",
    "        lon_match = abs(df['lon'] - target_lon) < tolerance\n",
    "        matches = df[lat_match & lon_match].index.tolist()\n",
    "        \n",
    "        if len(matches) > 0:\n",
    "            matched_indices.extend(matches)\n",
    "            if len(matches) > 1:\n",
    "                print(f\"    Warning: {len(matches)} rows matched for ({target_lat}, {target_lon})\")\n",
    "        else:\n",
    "            print(f\"    Warning: No match found for ({target_lat}, {target_lon})\")\n",
    "    \n",
    "    # Remove duplicates while preserving order\n",
    "    matched_indices = list(dict.fromkeys(matched_indices))\n",
    "    \n",
    "    # Extract matched rows\n",
    "    filtered_df = df.loc[matched_indices].copy()\n",
    "    \n",
    "    print(f\"  Matched rows: {len(filtered_df)}\")\n",
    "    \n",
    "    return filtered_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Process Each Variable and Export to CSV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T14:55:44.240217Z",
     "iopub.status.busy": "2025-12-14T14:55:44.240082Z",
     "iopub.status.idle": "2025-12-14T15:01:25.819841Z",
     "shell.execute_reply": "2025-12-14T15:01:25.818360Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Processing variable: tasmax\n",
      "============================================================\n",
      "  Loading data from: ACCESS_CM2_SSP585_tasmax.xlsx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Total rows in dataset: 612,226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Matched rows: 46\n",
      "  Exported to CSV: C:\\Users\\ibian\\Desktop\\ClimAdapt\\Anameka\\Anameka_South_ACCESS_CM2_SSP585\\Anameka_South_ACCESS_CM2_SSP585_tasmax.csv\n",
      "  Rows: 46, Columns: 32\n",
      "  Format: CSV (UTF-8 encoding)\n",
      "\n",
      "============================================================\n",
      "Processing variable: tasmin\n",
      "============================================================\n",
      "  Loading data from: ACCESS_CM2_SSP585_tasmin.xlsx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Total rows in dataset: 612,226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Matched rows: 46\n",
      "  Exported to CSV: C:\\Users\\ibian\\Desktop\\ClimAdapt\\Anameka\\Anameka_South_ACCESS_CM2_SSP585\\Anameka_South_ACCESS_CM2_SSP585_tasmin.csv\n",
      "  Rows: 46, Columns: 32\n",
      "  Format: CSV (UTF-8 encoding)\n",
      "\n",
      "============================================================\n",
      "Processing variable: pr\n",
      "============================================================\n",
      "  Loading data from: ACCESS_CM2_SSP585_pr.xlsx\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Total rows in dataset: 612,226\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Matched rows: 46\n",
      "  Exported to CSV: C:\\Users\\ibian\\Desktop\\ClimAdapt\\Anameka\\Anameka_South_ACCESS_CM2_SSP585\\Anameka_South_ACCESS_CM2_SSP585_pr.csv\n",
      "  Rows: 46, Columns: 30\n",
      "  Format: CSV (UTF-8 encoding)\n"
     ]
    }
   ],
   "source": [
    "# Process each variable\n",
    "results_summary = {}\n",
    "\n",
    "for variable in VARIABLES:\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"Processing variable: {variable}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Construct file path - check merged directory first\n",
    "    excel_file = os.path.join(DATA_DIR, f\"{MODEL_NAME}_{variable}.xlsx\")\n",
    "    \n",
    "    # If not found, check parent directory (for pr file)\n",
    "    if not os.path.exists(excel_file):\n",
    "        parent_dir = os.path.dirname(DATA_DIR)\n",
    "        excel_file_alt = os.path.join(parent_dir, f\"{MODEL_NAME}_{variable}.xlsx\")\n",
    "        if os.path.exists(excel_file_alt):\n",
    "            excel_file = excel_file_alt\n",
    "            print(f\"  Found file in parent directory: {excel_file}\")\n",
    "        else:\n",
    "            print(f\"  ERROR: File not found in either location:\")\n",
    "            print(f\"    - {os.path.join(DATA_DIR, f'{MODEL_NAME}_{variable}.xlsx')}\")\n",
    "            print(f\"    - {excel_file_alt}\")\n",
    "            continue\n",
    "    \n",
    "    # Extract data for filtered coordinates\n",
    "    filtered_data = extract_data_for_coordinates(\n",
    "        excel_file, \n",
    "        coords_df, \n",
    "        tolerance=COORD_TOLERANCE\n",
    "    )\n",
    "    \n",
    "    if len(filtered_data) == 0:\n",
    "        print(f\"  WARNING: No data extracted for {variable}\")\n",
    "        continue\n",
    "    \n",
    "    # Prepare output filename\n",
    "    output_filename = f\"Anameka_South_{MODEL_NAME}_{variable}.csv\"\n",
    "    output_path = os.path.join(OUTPUT_DIR, output_filename)\n",
    "    \n",
    "    # Export to CSV with explicit formatting\n",
    "    filtered_data.to_csv(\n",
    "        output_path, \n",
    "        index=False, \n",
    "        encoding='utf-8',\n",
    "        float_format='%.6f'  # Preserve precision for lat/lon and data values\n",
    "    )\n",
    "    print(f\"  Exported to CSV: {output_path}\")\n",
    "    print(f\"  Rows: {len(filtered_data)}, Columns: {len(filtered_data.columns)}\")\n",
    "    print(f\"  Format: CSV (UTF-8 encoding)\")\n",
    "    \n",
    "    # Store summary\n",
    "    results_summary[variable] = {\n",
    "        'rows': len(filtered_data),\n",
    "        'columns': len(filtered_data.columns),\n",
    "        'output_file': output_filename\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Summary Statistics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-12-14T15:01:25.826103Z",
     "iopub.status.busy": "2025-12-14T15:01:25.825398Z",
     "iopub.status.idle": "2025-12-14T15:01:25.835570Z",
     "shell.execute_reply": "2025-12-14T15:01:25.834201Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "EXTRACTION SUMMARY\n",
      "============================================================\n",
      "\n",
      "Filtered coordinates: 46\n",
      "\n",
      "Variables processed:\n",
      "  - tasmax:\n",
      "      Rows extracted: 46\n",
      "      Columns: 32\n",
      "      Output file: Anameka_South_ACCESS_CM2_SSP585_tasmax.csv (CSV format)\n",
      "  - tasmin:\n",
      "      Rows extracted: 46\n",
      "      Columns: 32\n",
      "      Output file: Anameka_South_ACCESS_CM2_SSP585_tasmin.csv (CSV format)\n",
      "  - pr:\n",
      "      Rows extracted: 46\n",
      "      Columns: 30\n",
      "      Output file: Anameka_South_ACCESS_CM2_SSP585_pr.csv (CSV format)\n",
      "\n",
      "Output directory: C:\\Users\\ibian\\Desktop\\ClimAdapt\\Anameka\\Anameka_South_ACCESS_CM2_SSP585\n",
      "\n",
      "All files exported as CSV format (UTF-8 encoding)\n",
      "CSV files are ready for analysis!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EXTRACTION SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nFiltered coordinates: {len(filtered_coords)}\")\n",
    "print(f\"\\nVariables processed:\")\n",
    "for variable, summary in results_summary.items():\n",
    "    print(f\"  - {variable}:\")\n",
    "    print(f\"      Rows extracted: {summary['rows']}\")\n",
    "    print(f\"      Columns: {summary['columns']}\")\n",
    "    print(f\"      Output file: {summary['output_file']} (CSV format)\")\n",
    "\n",
    "print(f\"\\nOutput directory: {OUTPUT_DIR}\")\n",
    "print(f\"\\nAll files exported as CSV format (UTF-8 encoding)\")\n",
    "print(\"CSV files are ready for analysis!\")\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
